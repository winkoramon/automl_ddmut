{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdd855e-d9c0-4e53-90d6-d1bb47405e62",
   "metadata": {},
   "source": [
    "#Evaluate on the default params on multiple algs\n",
    "1) AdaBoost\n",
    "2) Decision tree\n",
    "3) Random Forest\n",
    "4) Extra trees\n",
    "5) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0707af92-f7b1-4324-b2a5-93620036a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import joblib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76396cf4-f6c2-43e9-bb2a-ebf63c7882b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress only UserWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d965fe4f-32dd-44ce-bad6-5e6f115ce767",
   "metadata": {},
   "source": [
    "#Use extension to accelerate sklearn over Intel\n",
    "#Install from pip install scikit-learn-intelex\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cc1f8b-ac4e-4c42-9b44-67aa8b5b8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "from sklearn.metrics import roc_auc_score, f1_score, matthews_corrcoef, balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820d0276-a945-4185-8d05-367aef1f081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/korawich/Desktop/AutoML/Dataset/DDMut_data/'\n",
    "gbsig_path = '/home/korawich/Desktop/AutoML/Dataset/DDMut_data/Graph-based/'\n",
    "result_path = '/home/korawich/Desktop/AutoML/Dataset/DDMut_data/Results/'\n",
    "final_path = '/home/korawich/Desktop/AutoML/Dataset/DDMut_data/Final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ab21b7-a7d9-427e-a8da-717e371a0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output\n",
    "train_info_path  = final_path + 'train_info.csv'\n",
    "test_1_info_path = final_path + 'test_1_info.csv'\n",
    "test_2_info_path = final_path + 'test_2_info.csv'\n",
    "test_3_info_path = final_path + 'test_3_info.csv'\n",
    "\n",
    "train_X_path  = final_path + 'final_train_X.csv'\n",
    "test_1_X_path = final_path + 'final_test_1_X.csv'\n",
    "test_2_X_path = final_path + 'final_test_2_X.csv'\n",
    "test_3_X_path = final_path + 'final_test_3_X.csv'\n",
    "\n",
    "train_y_path  = final_path + 'train_y.csv'\n",
    "test_1_y_path = final_path + 'test_1_y.csv'\n",
    "test_2_y_path = final_path + 'test_2_y.csv'\n",
    "test_3_y_path = final_path + 'test_3_y.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c714c3af-23cd-4580-8a6f-60495d3d0662",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(train_X_path, index_col=0)\n",
    "X_test_1 = pd.read_csv(test_1_X_path, index_col=0)\n",
    "X_test_2 = pd.read_csv(test_2_X_path, index_col=0)\n",
    "X_test_3 = pd.read_csv(test_3_X_path, index_col=0)\n",
    "\n",
    "y_train = pd.read_csv(train_y_path, index_col=0)\n",
    "y_test_1 = pd.read_csv(test_1_y_path, index_col=0)\n",
    "y_test_2 = pd.read_csv(test_2_y_path, index_col=0)\n",
    "y_test_3 = pd.read_csv(test_3_y_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06885d73-bad9-4913-b326-c16a0ceff259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape =  (9028, 896)\n",
      "X_test_1.shape =  (552, 896)\n",
      "X_test_2.shape =  (1304, 896)\n",
      "X_test_3.shape =  (2024, 896)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape = ', X_train.shape)\n",
    "print('X_test_1.shape = ', X_test_1.shape)\n",
    "print('X_test_2.shape = ', X_test_2.shape)\n",
    "print('X_test_3.shape = ', X_test_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65b8c3e5-4371-46e9-9036-04a9f41d18ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/korawich/anaconda3/envs/atml_gen/lib/python3.12/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002bed32-2b11-463c-8459-c58e0e4ba7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running -  XGBoost\n",
      "running -  Linear Regression\n",
      "running -  Decision Tree\n",
      "running -  Random Forest\n"
     ]
    }
   ],
   "source": [
    "# List of regression models to test\n",
    "models = {\n",
    "    \"XGBoost\": XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Support Vector Regression\": SVR()\n",
    "}\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Dictionary to store the results\n",
    "results = []\n",
    "\n",
    "# List of test sets\n",
    "test_sets = [\n",
    "    ('Test Set 1', X_test_1, y_test_1),\n",
    "    ('Test Set 2', X_test_2, y_test_2),\n",
    "    ('Test Set 3', X_test_3, y_test_3)\n",
    "]\n",
    "\n",
    "scoring = ['neg_mean_squared_error', 'r2']\n",
    "\n",
    "# Iterate over each model, train, cross-validate, and evaluate on multiple test sets\n",
    "for name, model in models.items():\n",
    "    print('running - ', name)\n",
    "\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    rmse_scores = []\n",
    "    r2_scores = []\n",
    "    pearson_corrs = []\n",
    "    \n",
    "    for train_index, test_index in kfold.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.loc[train_index], X_train.loc[test_index]\n",
    "        y_train_fold, y_test_fold = y_train.loc[train_index], y_train.loc[test_index]\n",
    "        \n",
    "        # Train the model on the current fold\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred_fold = model.predict(X_test_fold)\n",
    "        \n",
    "        # Calculate RMSE, R2, and Pearson correlation\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred_fold))\n",
    "        r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "        pearson_corr, _ = pearsonr(y_test_fold.values.flatten(), y_pred_fold.flatten())\n",
    "        \n",
    "        # Store the scores\n",
    "        rmse_scores = np.append(rmse_scores, rmse)\n",
    "        r2_scores = np.append(r2_scores, r2)\n",
    "        pearson_corrs = np.append(pearson_corrs, pearson_corr)\n",
    "\n",
    "    # Train the model on the full training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    results.append({\"Model\": name, \n",
    "                    \"CV Mean RMSE (10-fold)\": round(np.mean(rmse_scores), 3), \n",
    "                    \"CV Std RMSE (10-fold)\": round(np.std(rmse_scores), 3),\n",
    "                    \"CV Mean R2 (10-fold)\": round(np.mean(r2_scores), 3),\n",
    "                    \"CV Std R2 (10-fold)\": round(np.std(r2_scores), 3),\n",
    "                    \"CV Mean Pearson (10-fold)\": round(np.mean(pearson_corrs), 3),\n",
    "                    \"CV Std Pearson (10-fold)\": round(np.std(pearson_corrs), 3),\n",
    "                    \"Test Set\": '10-fold CV'\n",
    "                   })\n",
    "    \n",
    "    # Evaluate the model on each test set\n",
    "    for test_name, X_test, y_test in test_sets:\n",
    "        # Predict on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate performance metrics on test data\n",
    "        rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        pearson_corr, _ = pearsonr(y_test.values.flatten(), y_pred.flatten())\n",
    "        \n",
    "        # Append results to the list\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Test Set\": test_name,\n",
    "            \"Test RMSE\": round(rmse_score, 3),\n",
    "            \"Test R2\": round(r2, 3),\n",
    "            \"Test Pearson\": round(pearson_corr, 3)\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df_all_save_path = result_path + 'benchmark_default_params_all.csv'\n",
    "results_df.to_csv(results_df_all_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e8d14-0b8f-4771-b026-9da9a629ac46",
   "metadata": {},
   "source": [
    "#FOR EACH FEATURE SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280438c-e4a9-4eb6-aed7-10f45b4bfdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "feat_list_path = '/home/korawich/Desktop/AutoML/Dataset/DDMut_data/Feat_list/'\n",
    "gbsig_feat_list_path = feat_list_path + 'gbsig_feat_list.csv'\n",
    "seq_feat_list_path = feat_list_path + 'seq_feat_list.csv'\n",
    "str_feat_list_path = feat_list_path + 'str_feat_list.csv'\n",
    "\n",
    "gbsig_feat_result_path = result_path + 'benchmark_default_params_gbsig.csv'\n",
    "seq_feat_result_path = result_path + 'benchmark_default_params_seq.csv'\n",
    "str_feat_result_path = result_path + 'benchmark_default_params_str.csv'\n",
    "\n",
    "gbs_feat = pd.read_csv(gbsig_feat_list_path, index_col=0)\n",
    "seq_feat = pd.read_csv(seq_feat_list_path, index_col=0)\n",
    "str_feat = pd.read_csv(str_feat_list_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774469d9-2325-4cfa-929e-b941502cf8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sets = [\n",
    "    ('seq_feat', seq_feat, seq_feat_result_path),\n",
    "    ('str_feat', str_feat, str_feat_result_path),\n",
    "    ('gbs_feat', gbs_feat, gbsig_feat_result_path)\n",
    "]\n",
    "\n",
    "for feat_name, feat_list, save_path in features_sets:\n",
    "    print('running feat - ', feat_name)\n",
    "        # List of regression models to test\n",
    "    models = {\n",
    "        \"XGBoost\": XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n",
    "        \"Random Forest\": RandomForestRegressor(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
    "        \"Support Vector Regression\": SVR()\n",
    "    }\n",
    "    \n",
    "    # Define 10-fold cross-validation\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Dictionary to store the results\n",
    "    results = []\n",
    "    \n",
    "    # List of test sets\n",
    "    test_sets = [\n",
    "        ('Test Set 1', X_test_1[feat_list], y_test_1),\n",
    "        ('Test Set 2', X_test_2[feat_list], y_test_2),\n",
    "        ('Test Set 3', X_test_3[feat_list], y_test_3)\n",
    "    ]\n",
    "    \n",
    "    scoring = ['neg_mean_squared_error', 'r2']\n",
    "    \n",
    "    # Iterate over each model, train, cross-validate, and evaluate on multiple test sets\n",
    "    for name, model in models.items():\n",
    "        print('running - ', name)\n",
    "    \n",
    "        kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "        \n",
    "        rmse_scores = []\n",
    "        r2_scores = []\n",
    "        pearson_corrs = []\n",
    "        \n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "            X_train_fold, X_test_fold = X_train.loc[train_index], X_train.loc[test_index]\n",
    "            y_train_fold, y_test_fold = y_train.loc[train_index], y_train.loc[test_index]\n",
    "            \n",
    "            # Train the model on the current fold\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred_fold = model.predict(X_test_fold)\n",
    "            \n",
    "            # Calculate RMSE, R2, and Pearson correlation\n",
    "            rmse = np.sqrt(mean_squared_error(y_test_fold, y_pred_fold))\n",
    "            r2 = r2_score(y_test_fold, y_pred_fold)\n",
    "            pearson_corr, _ = pearsonr(y_test_fold.values.flatten(), y_pred_fold.flatten())\n",
    "            \n",
    "            # Store the scores\n",
    "            rmse_scores = np.append(rmse_scores, rmse)\n",
    "            r2_scores = np.append(r2_scores, r2)\n",
    "            pearson_corrs = np.append(pearson_corrs, pearson_corr)\n",
    "    \n",
    "        # Train the model on the full training data\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        results.append({\"Model\": name, \n",
    "                        \"CV Mean RMSE (10-fold)\": round(np.mean(rmse_scores), 3), \n",
    "                        \"CV Std RMSE (10-fold)\": round(np.std(rmse_scores), 3),\n",
    "                        \"CV Mean R2 (10-fold)\": round(np.mean(r2_scores), 3),\n",
    "                        \"CV Std R2 (10-fold)\": round(np.std(r2_scores), 3),\n",
    "                        \"CV Mean Pearson (10-fold)\": round(np.mean(pearson_corrs), 3),\n",
    "                        \"CV Std Pearson (10-fold)\": round(np.std(pearson_corrs), 3),\n",
    "                        \"Test Set\": '10-fold CV'\n",
    "                       })\n",
    "        \n",
    "        # Evaluate the model on each test set\n",
    "        for test_name, X_test, y_test in test_sets:\n",
    "            # Predict on the test data\n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            # Calculate performance metrics on test data\n",
    "            rmse_score = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            pearson_corr, _ = pearsonr(y_test.values.flatten(), y_pred.flatten())\n",
    "            \n",
    "            # Append results to the list\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"Test Set\": test_name,\n",
    "                \"Test RMSE\": round(rmse_score, 3),\n",
    "                \"Test R2\": round(r2, 3),\n",
    "                \"Test Pearson\": round(pearson_corr, 3)\n",
    "            })\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7aef1c-c9a0-4f20-b8c5-c7f551dd8a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9373376e-91ea-4c1c-861e-cf37f15111c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef225ce-edd4-4c62-8c51-e993123aa028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff11b0c-1b1f-458c-988a-b17d483af1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6640bb-0228-4b35-8665-b96e9625654f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
